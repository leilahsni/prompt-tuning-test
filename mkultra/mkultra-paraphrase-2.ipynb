{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'GPT2SPTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import transformers\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "\n",
    "from transformers import AdamW, Adafactor\n",
    "from tqdm.notebook import tqdm\n",
    "from mkultra.tuning import GPT2PromptTuningLM\n",
    "from mkultra.tokenizers import GPT2SPTokenizerFast\n",
    "from mkultra.soft_prompt import SoftPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2PromptTuningLM.from_pretrained(\"gpt2\").half().to(\"cuda\")\n",
    "tokenizer = GPT2SPTokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('paraphrase-dataset.csv', sep=',')\n",
    "\n",
    "inputs = df['input'].to_list()\n",
    "target = df['target'].to_list()\n",
    "\n",
    "with open('paraphrase-dataset.txt', 'w') as outfile:\n",
    "    for i in range(len(df)):\n",
    "        outfile.write(f'Sentence : {inputs[i]}\\nParaphrase : {target[i]}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prompt length: 21 tokens\n"
     ]
    }
   ],
   "source": [
    "#----------------------------#\n",
    "#  Prompt Tuning Parameters  #\n",
    "#----------------------------#\n",
    "\n",
    "# This decides the length of your soft prompt in tokens.\n",
    "# They will be initialized from the first n tokens of your dataset.\n",
    "n_tokens = 20\n",
    "\n",
    "initial_prompt = \"\"\"A paraphrase is a different way to say the same thing. Paraphrase the following sentence.\\n\"\"\"\n",
    "\n",
    "if initial_prompt is not None:\n",
    "    print(f\"Initial prompt length: {len(tokenizer.encode(initial_prompt))} tokens\")\n",
    "\n",
    "# Decide the length of your training blocks in tokens.\n",
    "# Safe sizes for gpt-neo-2.7B-halved:\n",
    "#  - 700 on a Colab T4 (16GB)\n",
    "#  - 400 on a Colab K80 (12GB)\n",
    "#  - 32 on a GTX1080 (8GB)\n",
    "# If it seems a bit small, don't worry!\n",
    "# Soft prompts can be moved forward in context for the best effect.\n",
    "block_size = 32\n",
    "\n",
    "# Name your soft prompt project.\n",
    "sp_name = 'prompt-tuning-paraphrase-2'\n",
    "\n",
    "# What's the name of model you'll be using?\n",
    "model_name = 'gpt2'\n",
    "\n",
    "# Specify the model directory or huggingface name.\n",
    "model_dir = \"gpt2\"\n",
    "\n",
    "model_type = \"gpt2\"\n",
    "\n",
    "# Specify the path to the text file used for training.\n",
    "text_path = \"paraphrase-dataset.txt\"\n",
    "\n",
    "# Specify the project directory.\n",
    "project_dir = f\"./{sp_name}-{model_name}/\"\n",
    "\n",
    "# Checkpoint interval in steps.\n",
    "checkpoint_interval = 1\n",
    "\n",
    "# Evaluation interval in steps.\n",
    "eval_interval = 1\n",
    "\n",
    "# How many blocks to use for evaluation.\n",
    "eval_blocks = 20\n",
    "\n",
    "# Adafactor hyperparameters\n",
    "optimizer_params = {\n",
    "    # Fixed learning rate, recommend 1e-4 to 1e-3\n",
    "    \"lr\": 1e-3,\n",
    "    \n",
    "    # 1st momentum, recommend 0\n",
    "    \"beta1\": 0,\n",
    "\n",
    "    # 2nd momentum decay schedule, recommend -0.3 (lower is slower)\n",
    "    \"decay_rate\": -0.3,\n",
    "\n",
    "    # Weight decay, recommend 1e-2 (WI is sensitive to overfitting)\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \n",
    "    # Update scaling, recommend False\n",
    "    \"scale_parameter\": False,\n",
    "    \n",
    "    # Built-in LR scheduler, recommend False\n",
    "    \"relative_step\": False\n",
    "    }\n",
    "\n",
    "# Gradient accumulation steps.\n",
    "base_acc_steps = 30\n",
    "\n",
    "# Gradient accumulation schedule.\n",
    "# If '0', use a fixed gradient accumulation.\n",
    "acc_doubling_rate = 0\n",
    "\n",
    "# Stop training after this many evals without improvement.\n",
    "# If '0', don't stop early.\n",
    "plateau_steps = 10\n",
    "\n",
    "scheduler_params = {\n",
    "   \"num_warmup_steps\": 10,\n",
    "   \"num_cycles\": 4,\n",
    "   \"num_training_steps\": 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 13:48:31.033814: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-10 13:48:31.033848: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created project directory at ./prompt-tuning-paraphrase-2-gpt2/\n",
      "No checkpoints found\n"
     ]
    }
   ],
   "source": [
    "filename_for_checkpoint = lambda step: f\"{sp_name}-{model_name}-step-{step}.json\"\n",
    "loaded_sp = None\n",
    "project_files = None\n",
    "\n",
    "# Look for existing project directory\n",
    "try:\n",
    "    os.makedirs(project_dir)\n",
    "    print(f\"Created project directory at {project_dir}\")\n",
    "except FileExistsError:\n",
    "    print(f\"Found project directory at {project_dir}\")\n",
    "\n",
    "# Look for existing checkpoints\n",
    "project_files = os.listdir(project_dir)\n",
    "if project_files is not None:\n",
    "    checkpoint_files = [check_file for check_file in project_files if ('-step-' in check_file) ]\n",
    "\n",
    "    if len(checkpoint_files) > 0:\n",
    "        highest_step = max([ int(check_file[check_file.rfind('-step-')+6:-5]) for check_file in checkpoint_files ])\n",
    "        loaded_sp = SoftPrompt.from_file( os.path.join(project_dir, filename_for_checkpoint(highest_step)) )\n",
    "        print(f\"Loading latest checkpoint: {highest_step}\")\n",
    "    else:\n",
    "        print(\"No checkpoints found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (39144 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tokens.json exists, creating it...\n",
      "Length of text: 39144 tokens\n",
      "Number of blocks: 1224, each 32 tokens\n",
      "No block_order.json exists, creating it...\n"
     ]
    }
   ],
   "source": [
    "text_tokenized = None\n",
    "tokens_path = os.path.join(project_dir,\"tokens.json\")\n",
    "\n",
    "# See if we already have a tokens file\n",
    "try:\n",
    "    with open(tokens_path, 'r', encoding='utf-8') as file:\n",
    "        text_tokenized = json.load(file)\n",
    "        print(\"Loaded existing tokens.json file\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"No tokens.json exists, creating it...\")\n",
    "\n",
    "# If not, make one now\n",
    "if text_tokenized is None:\n",
    "\n",
    "    with open(text_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    text_tokenized = tokenizer.encode(text)\n",
    "    \n",
    "    with open(tokens_path, 'x', encoding='utf-8') as file:\n",
    "        json.dump(text_tokenized, file)\n",
    "\n",
    "text_length = len(text_tokenized)\n",
    "num_blocks = math.ceil(text_length/block_size)\n",
    "\n",
    "print(f\"Length of text: {len(text_tokenized)} tokens\")\n",
    "print(f\"Number of blocks: {num_blocks}, each {block_size} tokens\")\n",
    "\n",
    "# Partition tokens into blocks\n",
    "blocks = list()\n",
    "for block_num in range(num_blocks):\n",
    "    start = block_num * block_size\n",
    "    end = min(start + block_size, text_length)\n",
    "    blocks.append( text_tokenized[start:end] )\n",
    "\n",
    "block_order_path = os.path.join(project_dir, \"block_order.json\")\n",
    "\n",
    "# See if we already have a block_order file\n",
    "try:\n",
    "    with open(block_order_path, 'r', encoding='utf-8') as file:\n",
    "        block_order = json.load(file)\n",
    "        print(\"Loaded existing block_order.json file\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"No block_order.json exists, creating it...\")\n",
    "    block_order = [*range(num_blocks)]\n",
    "\n",
    "    with open(block_order_path, 'x', encoding='utf-8') as file:\n",
    "        json.dump(block_order, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prompt length: 21\n"
     ]
    }
   ],
   "source": [
    "if loaded_sp is None:\n",
    "    if initial_prompt is None:\n",
    "        model.initialize_soft_prompt(n_tokens=n_tokens)\n",
    "    else:\n",
    "        initial_sp = SoftPrompt.from_string(initial_prompt, model, tokenizer)\n",
    "        print(f\"Initial prompt length: {len(initial_sp)}\")\n",
    "        model.set_soft_prompt(initial_sp)\n",
    "\n",
    "    sp_step = 0\n",
    "    eval_loss = 100\n",
    "else:\n",
    "    model.set_soft_prompt(loaded_sp)\n",
    "    sp_step = loaded_sp._metadata['step']\n",
    "    eval_loss = loaded_sp._metadata['loss']\n",
    "    \n",
    "num_training_steps = scheduler_params['num_training_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed soft params to optimizer\n",
    "optimizer_params['params'] = [model.get_soft_params()]\n",
    "optimizer = Adafactor(**optimizer_params)\n",
    "optimizer.state['step'] = sp_step\n",
    "\n",
    "scheduler_params['optimizer'] = optimizer\n",
    "scheduler = transformers.get_cosine_with_hard_restarts_schedule_with_warmup(**scheduler_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2746a152d646a4ae183985daba8998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "epoch : 2\n",
      "epoch : 3\n",
      "epoch : 4\n",
      "epoch : 5\n",
      "epoch : 6\n",
      "epoch : 7\n",
      "epoch : 8\n",
      "epoch : 9\n",
      "epoch : 10\n",
      "epoch : 11\n",
      "epoch : 12\n",
      "epoch : 13\n",
      "epoch : 14\n",
      "epoch : 15\n",
      "epoch : 16\n",
      "epoch : 17\n",
      "epoch : 18\n",
      "epoch : 19\n",
      "epoch : 20\n",
      "epoch : 21\n",
      "epoch : 22\n",
      "epoch : 23\n",
      "epoch : 24\n",
      "epoch : 25\n",
      "epoch : 26\n",
      "epoch : 27\n",
      "epoch : 28\n",
      "epoch : 29\n",
      "epoch : 30\n",
      "epoch : 31\n",
      "epoch : 32\n",
      "epoch : 33\n",
      "epoch : 34\n",
      "epoch : 35\n",
      "epoch : 36\n",
      "epoch : 37\n",
      "epoch : 38\n",
      "epoch : 39\n",
      "epoch : 40\n",
      "epoch : 41\n",
      "epoch : 42\n",
      "epoch : 43\n",
      "epoch : 44\n",
      "epoch : 45\n",
      "epoch : 46\n",
      "epoch : 47\n",
      "epoch : 48\n",
      "epoch : 49\n",
      "epoch : 50\n",
      "epoch : 51\n",
      "epoch : 52\n",
      "epoch : 53\n",
      "epoch : 54\n",
      "epoch : 55\n",
      "epoch : 56\n",
      "epoch : 57\n",
      "epoch : 58\n",
      "epoch : 59\n",
      "epoch : 60\n",
      "epoch : 61\n",
      "epoch : 62\n",
      "epoch : 63\n",
      "epoch : 64\n",
      "epoch : 65\n",
      "epoch : 66\n",
      "epoch : 67\n",
      "epoch : 68\n",
      "epoch : 69\n",
      "epoch : 70\n",
      "epoch : 71\n",
      "epoch : 72\n",
      "epoch : 73\n",
      "epoch : 74\n",
      "epoch : 75\n",
      "epoch : 76\n",
      "epoch : 77\n",
      "epoch : 78\n",
      "epoch : 79\n",
      "epoch : 80\n",
      "epoch : 81\n",
      "epoch : 82\n",
      "epoch : 83\n",
      "epoch : 84\n",
      "epoch : 85\n",
      "epoch : 86\n",
      "epoch : 87\n",
      "epoch : 88\n",
      "epoch : 89\n",
      "epoch : 90\n",
      "epoch : 91\n",
      "epoch : 92\n",
      "epoch : 93\n",
      "epoch : 94\n",
      "epoch : 95\n",
      "epoch : 96\n",
      "epoch : 97\n",
      "epoch : 98\n",
      "epoch : 99\n",
      "epoch : 100\n",
      "epoch : 101\n",
      "epoch : 102\n",
      "epoch : 103\n",
      "epoch : 104\n",
      "epoch : 105\n",
      "epoch : 106\n",
      "epoch : 107\n",
      "epoch : 108\n",
      "epoch : 109\n",
      "epoch : 110\n",
      "epoch : 111\n",
      "epoch : 112\n",
      "epoch : 113\n",
      "epoch : 114\n",
      "epoch : 115\n",
      "epoch : 116\n",
      "epoch : 117\n",
      "epoch : 118\n",
      "epoch : 119\n",
      "epoch : 120\n",
      "epoch : 121\n",
      "epoch : 122\n",
      "epoch : 123\n",
      "epoch : 124\n",
      "epoch : 125\n",
      "epoch : 126\n",
      "epoch : 127\n",
      "epoch : 128\n",
      "epoch : 129\n",
      "epoch : 130\n",
      "epoch : 131\n",
      "epoch : 132\n",
      "epoch : 133\n",
      "epoch : 134\n",
      "epoch : 135\n",
      "epoch : 136\n",
      "epoch : 137\n",
      "epoch : 138\n",
      "epoch : 139\n",
      "epoch : 140\n",
      "epoch : 141\n",
      "epoch : 142\n",
      "epoch : 143\n",
      "epoch : 144\n",
      "epoch : 145\n",
      "epoch : 146\n",
      "epoch : 147\n",
      "epoch : 148\n",
      "epoch : 149\n",
      "epoch : 150\n",
      "epoch : 151\n",
      "epoch : 152\n",
      "epoch : 153\n",
      "epoch : 154\n",
      "epoch : 155\n",
      "epoch : 156\n",
      "epoch : 157\n",
      "epoch : 158\n",
      "epoch : 159\n",
      "epoch : 160\n",
      "epoch : 161\n",
      "epoch : 162\n",
      "epoch : 163\n",
      "epoch : 164\n",
      "epoch : 165\n",
      "epoch : 166\n",
      "epoch : 167\n",
      "epoch : 168\n",
      "epoch : 169\n",
      "epoch : 170\n",
      "epoch : 171\n",
      "epoch : 172\n",
      "epoch : 173\n",
      "epoch : 174\n",
      "epoch : 175\n",
      "epoch : 176\n",
      "epoch : 177\n",
      "epoch : 178\n",
      "epoch : 179\n",
      "epoch : 180\n",
      "epoch : 181\n",
      "epoch : 182\n",
      "epoch : 183\n",
      "epoch : 184\n",
      "epoch : 185\n",
      "epoch : 186\n",
      "epoch : 187\n",
      "epoch : 188\n",
      "epoch : 189\n",
      "epoch : 190\n",
      "epoch : 191\n",
      "epoch : 192\n",
      "epoch : 193\n",
      "epoch : 194\n",
      "epoch : 195\n",
      "epoch : 196\n",
      "epoch : 197\n",
      "epoch : 198\n",
      "epoch : 199\n",
      "epoch : 200\n",
      "epoch : 201\n",
      "epoch : 202\n",
      "epoch : 203\n",
      "epoch : 204\n",
      "epoch : 205\n",
      "epoch : 206\n",
      "epoch : 207\n",
      "epoch : 208\n",
      "epoch : 209\n",
      "epoch : 210\n",
      "epoch : 211\n",
      "epoch : 212\n",
      "epoch : 213\n",
      "epoch : 214\n",
      "epoch : 215\n",
      "epoch : 216\n",
      "epoch : 217\n",
      "epoch : 218\n",
      "epoch : 219\n",
      "epoch : 220\n",
      "epoch : 221\n",
      "epoch : 222\n",
      "epoch : 223\n",
      "epoch : 224\n",
      "epoch : 225\n",
      "epoch : 226\n",
      "epoch : 227\n",
      "epoch : 228\n",
      "epoch : 229\n",
      "epoch : 230\n",
      "epoch : 231\n",
      "epoch : 232\n",
      "epoch : 233\n",
      "epoch : 234\n",
      "epoch : 235\n",
      "epoch : 236\n",
      "epoch : 237\n",
      "epoch : 238\n",
      "epoch : 239\n",
      "epoch : 240\n",
      "epoch : 241\n",
      "epoch : 242\n",
      "epoch : 243\n",
      "epoch : 244\n",
      "epoch : 245\n",
      "epoch : 246\n",
      "epoch : 247\n",
      "epoch : 248\n",
      "epoch : 249\n",
      "epoch : 250\n",
      "epoch : 251\n",
      "epoch : 252\n",
      "epoch : 253\n",
      "epoch : 254\n",
      "epoch : 255\n",
      "epoch : 256\n",
      "epoch : 257\n",
      "epoch : 258\n",
      "epoch : 259\n",
      "epoch : 260\n",
      "epoch : 261\n",
      "epoch : 262\n",
      "epoch : 263\n",
      "epoch : 264\n",
      "epoch : 265\n",
      "epoch : 266\n",
      "epoch : 267\n",
      "epoch : 268\n",
      "epoch : 269\n",
      "epoch : 270\n",
      "epoch : 271\n",
      "epoch : 272\n",
      "epoch : 273\n",
      "epoch : 274\n",
      "epoch : 275\n",
      "epoch : 276\n",
      "epoch : 277\n",
      "epoch : 278\n",
      "epoch : 279\n",
      "epoch : 280\n",
      "epoch : 281\n",
      "epoch : 282\n",
      "epoch : 283\n",
      "epoch : 284\n",
      "epoch : 285\n",
      "epoch : 286\n",
      "epoch : 287\n",
      "epoch : 288\n",
      "epoch : 289\n",
      "epoch : 290\n",
      "epoch : 291\n",
      "epoch : 292\n",
      "epoch : 293\n",
      "epoch : 294\n",
      "epoch : 295\n",
      "epoch : 296\n",
      "epoch : 297\n",
      "epoch : 298\n",
      "epoch : 299\n",
      "epoch : 300\n",
      "epoch : 301\n",
      "epoch : 302\n",
      "epoch : 303\n",
      "epoch : 304\n",
      "epoch : 305\n",
      "epoch : 306\n",
      "epoch : 307\n",
      "epoch : 308\n",
      "epoch : 309\n",
      "epoch : 310\n",
      "epoch : 311\n",
      "epoch : 312\n",
      "epoch : 313\n",
      "epoch : 314\n",
      "epoch : 315\n",
      "epoch : 316\n",
      "epoch : 317\n",
      "epoch : 318\n",
      "epoch : 319\n",
      "epoch : 320\n",
      "epoch : 321\n",
      "epoch : 322\n",
      "epoch : 323\n",
      "epoch : 324\n",
      "epoch : 325\n",
      "epoch : 326\n",
      "epoch : 327\n",
      "epoch : 328\n",
      "epoch : 329\n",
      "epoch : 330\n",
      "epoch : 331\n",
      "epoch : 332\n",
      "epoch : 333\n",
      "epoch : 334\n",
      "epoch : 335\n",
      "epoch : 336\n",
      "epoch : 337\n",
      "epoch : 338\n",
      "epoch : 339\n",
      "epoch : 340\n",
      "epoch : 341\n",
      "epoch : 342\n",
      "epoch : 343\n",
      "epoch : 344\n",
      "epoch : 345\n",
      "epoch : 346\n",
      "epoch : 347\n",
      "epoch : 348\n",
      "epoch : 349\n",
      "epoch : 350\n",
      "epoch : 351\n",
      "epoch : 352\n",
      "epoch : 353\n",
      "epoch : 354\n",
      "epoch : 355\n",
      "epoch : 356\n",
      "epoch : 357\n",
      "epoch : 358\n",
      "epoch : 359\n",
      "epoch : 360\n",
      "epoch : 361\n",
      "epoch : 362\n",
      "epoch : 363\n",
      "epoch : 364\n",
      "epoch : 365\n",
      "epoch : 366\n",
      "epoch : 367\n",
      "epoch : 368\n",
      "epoch : 369\n",
      "epoch : 370\n",
      "epoch : 371\n",
      "epoch : 372\n",
      "No improvement for 10 evals\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "loss_log_path = os.path.join(project_dir,\"loss_log.csv\")\n",
    "bar = tqdm(total=num_training_steps)\n",
    "optimizer.state['step'] = sp_step\n",
    "evals_since_last_improvement = 0\n",
    "best_eval = float('inf')\n",
    "\n",
    "# Fix eval order\n",
    "eval_order = [*range(num_blocks)]\n",
    "random.seed(1234)\n",
    "random.shuffle(eval_order)\n",
    "\n",
    "# Function for gradient accumulation scheduling\n",
    "def get_acc_steps(sp_step):\n",
    "    if acc_doubling_rate != 0:\n",
    "        return round(base_acc_steps * math.pow(2, (sp_step / acc_doubling_rate)))\n",
    "    else:\n",
    "        return base_acc_steps\n",
    "\n",
    "for session_step in range(num_training_steps):\n",
    "      model.train()\n",
    "      print(f\"epoch : {session_step+1}\")\n",
    "\n",
    "      acc_steps = get_acc_steps(sp_step)\n",
    "\n",
    "      for i in range(acc_steps):\n",
    "          idx = (sp_step*acc_steps + i) % num_blocks\n",
    "\n",
    "          # Shuffle blocks every epoch\n",
    "          if idx == 0:\n",
    "              random.shuffle(block_order)\n",
    "              with open(block_order_path, 'w', encoding='utf-8') as file:\n",
    "                  json.dump(block_order, file)\n",
    "\n",
    "          block = blocks[block_order[idx]]\n",
    "\n",
    "          input_ids = torch.LongTensor(block).unsqueeze(0).cuda().detach()\n",
    "          \n",
    "          # Forward pass and optimize\n",
    "          outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "          loss = outputs.loss\n",
    "          loss.backward()\n",
    "\n",
    "          instant_loss = loss.item()\n",
    "          if math.isnan(instant_loss):\n",
    "              torch.cuda.empty_cache()\n",
    "              raise KeyboardInterrupt\n",
    "\n",
    "          # Discard tensor that was moved to GPU\n",
    "          del input_ids\n",
    "          torch.cuda.empty_cache()\n",
    "\n",
    "      # Accumulate gradients\n",
    "      optimizer.step()\n",
    "      lr = optimizer.param_groups[0][\"lr\"]\n",
    "      scheduler.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      if math.isnan(instant_loss):\n",
    "          torch.cuda.empty_cache()\n",
    "          raise KeyboardInterrupt\n",
    "\n",
    "      # Evaluate model and plot loss\n",
    "      if sp_step%eval_interval == 0:\n",
    "          model.eval()\n",
    "          torch.cuda.empty_cache()\n",
    "          eval_loss = 0\n",
    "\n",
    "          with torch.no_grad():\n",
    "              for eval_step in range(eval_blocks):\n",
    "                  block = blocks[eval_order[eval_step]]\n",
    "                  input_ids = torch.LongTensor(block).unsqueeze(0).cuda().detach()\n",
    "                  eval_loss += model(input_ids=input_ids, labels=input_ids).loss.item()\n",
    "                  \n",
    "                  # Discard tensor that was moved to GPU\n",
    "                  del input_ids\n",
    "                  torch.cuda.empty_cache()\n",
    "\n",
    "          eval_loss /= eval_blocks\n",
    "\n",
    "          with open(loss_log_path, 'a', encoding='utf-8') as file:\n",
    "              file.write(f\"{sp_step},{eval_loss}\\n\")\n",
    "          \n",
    "          # Stop if loss has plateaued\n",
    "          if plateau_steps != 0:\n",
    "              if eval_loss < best_eval:\n",
    "                  best_eval = eval_loss\n",
    "                  evals_since_last_improvement = 0\n",
    "              else:\n",
    "                  evals_since_last_improvement += 1\n",
    "              if evals_since_last_improvement > plateau_steps:\n",
    "                  print(f\"No improvement for {plateau_steps} evals\")\n",
    "                  break\n",
    "\n",
    "      # Save checkpoint every so often\n",
    "      if sp_step%checkpoint_interval == 0:\n",
    "          sp = SoftPrompt.from_tuning_model(model,\n",
    "              {\"name\" : sp_name + f\"-step-{sp_step}\",\n",
    "               \"step\"  : sp_step,\n",
    "               \"loss\"  : eval_loss})\n",
    "          sp.to_file( os.path.join( project_dir,filename_for_checkpoint(sp_step) ) )\n",
    "\n",
    "      bar.set_postfix({\n",
    "          \"Model Step\" : sp_step,\n",
    "          \"Eval Loss\"  : \"{el:.5f}\".format(el=eval_loss),\n",
    "          \"Acc Steps\"  : acc_steps,\n",
    "          \"LR\"         : lr\n",
    "      })\n",
    "      bar.update(1)\n",
    "      sp_step += 1\n",
    "\n",
    "# Save a checkpoint once done\n",
    "sp = SoftPrompt.from_tuning_model(model,\n",
    "    {\"name\"  : sp_name + f\"-step-{sp_step}\",\n",
    "     \"step\"  : sp_step,\n",
    "     \"loss\"  : eval_loss})\n",
    "sp.to_file( os.path.join( project_dir,filename_for_checkpoint(sp_step) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  del input_ids\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min loss reached at 361 epoch.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "with open(loss_log_path, 'r') as file:\n",
    "    array = np.loadtxt(file, delimiter=\",\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(array[:, 0], array[:, 1])\n",
    "\n",
    "colnames = ['index', 'loss'] \n",
    "losses = pd.read_csv(loss_log_path, sep=',', index_col = [0], names = colnames)\n",
    "min_loss = min(losses['loss'])\n",
    "min_loss_idx = losses.index[losses['loss'] == min_loss][0]+1\n",
    "\n",
    "print(f'min loss reached at {min_loss_idx} epoch.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : What's the weather like today?\n",
      "Paraphrase : How to get around in New South Wales? Paraphernalia: what kinds do you have at this hour, which ones are they getting rid of and why has it become popular with teenagers. Sentences:-What was going on yesterday that caused my wife (not her husband) suffering such a big headache as I can't believe how bad things felt inside me..sentencing:-Whois your name & date from who or where did i come across these pictures?:My Wife Has Been Hailing From Tasmania So Windy At Work For The Day/Night... Reply - Follow- Quote This is very hard news for Australia because there aren�t adequate facilities under Australian laws __________________\n",
      "\n",
      "The first answer will be given when she returns home after having been through all those years´s work. You remember last time we were doing laundry some people showed up too late so our hair got stained red pretty quickly! In contrast you never know before but maybe soon every one here might see about ten more\n"
     ]
    }
   ],
   "source": [
    "# Try generating with your model\n",
    "model.eval()\n",
    "\n",
    "# Restore soft prompt from checkpoint\n",
    "# (Use above graph to find a good stopping point and check project directory for valid checkpoints)\n",
    "sp = SoftPrompt.from_file(os.path.join(project_dir, filename_for_checkpoint(min_loss_idx)) )\n",
    "model.set_soft_prompt(sp)\n",
    "\n",
    "test = \"Sentence : What's the weather like today ?\\nParaphrase :\"\n",
    "\n",
    "call = tokenizer(test, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "basic_output = model.generate(\n",
    "    input_ids=call,\n",
    "    do_sample=True,\n",
    "    min_length=call.shape[-1] + 200,\n",
    "    max_length=call.shape[-1] + 200,\n",
    "    temperature=1.0,\n",
    "    tfs = 0.9,\n",
    "    repetition_penalty = 3.0,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(tokenizer.decode(basic_output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mkultra-env]",
   "language": "python",
   "name": "conda-env-mkultra-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
